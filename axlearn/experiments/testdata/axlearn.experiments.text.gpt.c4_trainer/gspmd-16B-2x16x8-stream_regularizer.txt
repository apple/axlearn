====================weight_decay_scale root.optimizer====================
decoder/emb/token_emb/weight: 1
decoder/output_norm/scale: 1
decoder/transformer/pipeline/layer/layer0/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer0/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer0/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer0/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer0/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer0/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer1/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer1/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer1/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer1/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer1/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer1/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer10/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer10/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer10/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer10/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer10/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer10/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer11/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer11/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer11/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer11/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer11/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer11/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer12/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer12/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer12/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer12/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer12/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer12/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer13/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer13/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer13/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer13/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer13/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer13/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer14/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer14/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer14/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer14/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer14/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer14/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer15/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer15/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer15/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer15/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer15/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer15/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer16/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer16/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer16/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer16/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer16/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer16/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer17/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer17/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer17/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer17/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer17/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer17/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer18/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer18/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer18/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer18/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer18/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer18/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer19/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer19/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer19/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer19/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer19/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer19/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer2/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer2/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer2/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer2/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer2/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer2/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer20/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer20/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer20/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer20/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer20/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer20/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer21/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer21/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer21/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer21/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer21/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer21/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer22/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer22/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer22/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer22/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer22/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer22/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer23/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer23/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer23/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer23/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer23/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer23/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer24/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer24/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer24/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer24/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer24/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer24/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer25/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer25/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer25/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer25/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer25/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer25/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer26/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer26/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer26/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer26/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer26/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer26/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer27/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer27/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer27/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer27/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer27/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer27/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer28/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer28/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer28/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer28/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer28/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer28/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer29/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer29/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer29/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer29/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer29/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer29/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer3/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer3/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer3/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer3/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer3/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer3/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer30/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer30/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer30/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer30/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer30/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer30/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer31/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer31/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer31/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer31/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer31/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer31/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer4/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer4/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer4/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer4/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer4/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer4/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer5/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer5/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer5/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer5/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer5/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer5/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer6/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer6/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer6/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer6/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer6/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer6/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer7/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer7/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer7/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer7/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer7/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer7/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer8/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer8/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer8/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer8/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer8/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer8/self_attention/norm/scale: 1
decoder/transformer/pipeline/layer/layer9/feed_forward/linear1/weight: 1
decoder/transformer/pipeline/layer/layer9/feed_forward/linear2/weight: 1
decoder/transformer/pipeline/layer/layer9/feed_forward/norm/scale: 1
decoder/transformer/pipeline/layer/layer9/self_attention/attention/i_proj/qkv_proj/weight: 1
decoder/transformer/pipeline/layer/layer9/self_attention/attention/o_proj/weight: 1
decoder/transformer/pipeline/layer/layer9/self_attention/norm/scale: 1
