batch_axis_names[0]: 'data'
batch_axis_names[1]: 'expert'
batch_axis_names[2]: 'fsdp'
batch_axis_names[3]: 'seq'
checkpointer.gc_loop_interval_seconds: 60
checkpointer.keep_every_n_steps: 50000
checkpointer.keep_last_n: 3
checkpointer.klass: 'axlearn.common.checkpointer.Checkpointer'
checkpointer.save_policy.fn: 'axlearn.common.checkpointer.every_n_steps_and_last_policy'
checkpointer.save_policy.max_step: 983040
checkpointer.save_policy.min_step: 1
checkpointer.save_policy.n: 5000
checkpointer.storage.klass: 'axlearn.common.checkpointer.TensorStoreStateStorage'
checkpointer.storage.timeout_secs: 3600
evalers['train'].eval_dtype: 'jax.numpy.bfloat16'
evalers['train'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['train'].eval_policy.max_step: 983040
evalers['train'].eval_policy.min_step: 1
evalers['train'].eval_policy.n: 5000
evalers['train'].input.batcher.fn: 'axlearn.common.input_tf_data.per_feed_batch'
evalers['train'].input.batcher.pad_example_fn: 'axlearn.common.input_tf_data.default_pad_example_fn'
evalers['train'].input.batcher.prefetch_buffer_size: -1
evalers['train'].input.input_dispatcher.global_logical_batch_size: 2048
evalers['train'].input.input_dispatcher.klass: 'axlearn.common.input_dispatch.InputDispatcher'
evalers['train'].input.is_training: False
evalers['train'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['train'].input.processor.fn: 'axlearn.common.input_tf_data.identity'
evalers['train'].input.source.dataset_name: 'c4/en:3.0.1'
evalers['train'].input.source.fn: 'axlearn.experiments.text.gpt.common.tfds_input'
evalers['train'].input.source.is_training: False
evalers['train'].input.source.max_sequence_length: 8192
evalers['train'].input.source.replace_newlines_with: '\n'
evalers['train'].input.source.split: 'train[:8192]'
evalers['train'].input.source.train_shuffle_buffer_size: 16384
evalers['train'].input.source.vocab_cfg.filename: 'Llama-3-tokenizer.json'
evalers['train'].input.source.vocab_cfg.klass: 'axlearn.experiments.text.gpt.vocabulary_fuji_v3.FujiV3Vocabulary'
evalers['train'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['train'].metric_calculator.klass: 'axlearn.common.evaler.ModelSummaryAccumulator'
evalers['train'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['train'].metric_calculator.model_method: 'forward'
evalers['train'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['train'].summary_writer.write_every_n_steps: 1
evalers['validation'].eval_dtype: 'jax.numpy.bfloat16'
evalers['validation'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['validation'].eval_policy.max_step: 983040
evalers['validation'].eval_policy.min_step: 1
evalers['validation'].eval_policy.n: 5000
evalers['validation'].input.batcher.fn: 'axlearn.common.input_tf_data.per_feed_batch'
evalers['validation'].input.batcher.pad_example_fn: 'axlearn.common.input_tf_data.default_pad_example_fn'
evalers['validation'].input.batcher.prefetch_buffer_size: -1
evalers['validation'].input.input_dispatcher.global_logical_batch_size: 2048
evalers['validation'].input.input_dispatcher.klass: 'axlearn.common.input_dispatch.InputDispatcher'
evalers['validation'].input.is_training: False
evalers['validation'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['validation'].input.processor.fn: 'axlearn.common.input_tf_data.identity'
evalers['validation'].input.source.dataset_name: 'c4/en:3.0.1'
evalers['validation'].input.source.fn: 'axlearn.experiments.text.gpt.common.tfds_input'
evalers['validation'].input.source.is_training: False
evalers['validation'].input.source.max_sequence_length: 8192
evalers['validation'].input.source.replace_newlines_with: '\n'
evalers['validation'].input.source.split: 'validation'
evalers['validation'].input.source.train_shuffle_buffer_size: 16384
evalers['validation'].input.source.vocab_cfg.filename: 'Llama-3-tokenizer.json'
evalers['validation'].input.source.vocab_cfg.klass: 'axlearn.experiments.text.gpt.vocabulary_fuji_v3.FujiV3Vocabulary'
evalers['validation'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['validation'].metric_calculator.klass: 'axlearn.common.evaler.ModelSummaryAccumulator'
evalers['validation'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['validation'].metric_calculator.model_method: 'forward'
evalers['validation'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['validation'].summary_writer.write_every_n_steps: 1
input.batcher.fn: 'axlearn.common.input_tf_data.per_feed_batch'
input.batcher.pad_example_fn: 'axlearn.common.input_tf_data.default_pad_example_fn'
input.batcher.prefetch_buffer_size: -1
input.input_dispatcher.global_logical_batch_size: 2048
input.input_dispatcher.klass: 'axlearn.common.input_dispatch.InputDispatcher'
input.input_partitioner.fn: 'axlearn.common.input_base.partition_by_path_rank'
input.input_partitioner.path_rank_to_partition[(None, 1)]: PartitionSpec(('data', 'expert', 'fsdp'),)
input.input_partitioner.path_rank_to_partition[(None, 2)]: PartitionSpec(('data', 'expert', 'fsdp'), 'seq')
input.is_training: True
input.klass: 'axlearn.common.input_tf_data.Input'
input.processor.fn: 'axlearn.common.input_tf_data.identity'
input.source.data_mixture_components[0]['name']: 'c4/en:3.0.1'
input.source.data_mixture_components[0]['weight']: 1.0
input.source.data_mixture_components[0]['shuffle_buffer_size']: 8192
input.source.data_mixture_components[0]['split']: 'train'
input.source.data_mixture_components[0]['info']: ''
input.source.fn: 'axlearn.experiments.text.gpt.common.mixture_train_input_source'
input.source.max_sequence_length: 8192
input.source.preprocessor.fn: 'axlearn.common.input_lm.lm_text_preprocessor'
input.source.preprocessor.max_padding_fraction: 0.5
input.source.preprocessor.shuffle_buffer_size: 8192
input.source.preprocessor.window_size: 128
input.source.replace_newlines_with: '<n>'
input.source.vocab_cfg.filename: 'Llama-3-tokenizer.json'
input.source.vocab_cfg.klass: 'axlearn.experiments.text.gpt.vocabulary_fuji_v3.FujiV3Vocabulary'
klass: 'axlearn.common.trainer.SpmdTrainer'
learner.ema.fn: 'axlearn.common.optimizers.param_ema'
learner.enable_per_variable_summaries: False
learner.klass: 'axlearn.common.learner.Learner'
learner.optimizer.args[0].eps: 1e-08
learner.optimizer.args[0].fn: 'axlearn.common.optimizers.clip_by_global_norm'
learner.optimizer.args[0].max_norm: 1
learner.optimizer.args[1].b1: 0.9
learner.optimizer.args[1].b2: 0.95
learner.optimizer.args[1].eps: 1e-08
learner.optimizer.args[1].fn: 'axlearn.common.optimizers.adamw_decoupled_optimizer'
learner.optimizer.args[1].learning_rate: 0.0003
learner.optimizer.args[1].update_schedule.alpha: 0.1
learner.optimizer.args[1].update_schedule.begin_value: 0.0
learner.optimizer.args[1].update_schedule.fn: 'axlearn.common.schedule.cosine_with_linear_warmup'
learner.optimizer.args[1].update_schedule.max_step: 983040
learner.optimizer.args[1].update_schedule.peak_lr: 1.0
learner.optimizer.args[1].update_schedule.warmup_steps: 2000
learner.optimizer.args[1].weight_decay: 0.1
learner.optimizer.fn: 'axlearn.common.optimizers.chain'
max_step: 983040
mesh_axis_names[0]: 'pipeline'
mesh_axis_names[1]: 'data'
mesh_axis_names[2]: 'expert'
mesh_axis_names[3]: 'fsdp'
mesh_axis_names[4]: 'seq'
mesh_axis_names[5]: 'model'
mesh_rules[0][0]: 'neuron-(trn2|trn2n).48xlarge-64'
mesh_rules[0][1].config_modifiers[0].klass: 'axlearn.common.trainer_config_modifier.MeshShapeModifier'
mesh_rules[0][1].config_modifiers[0].mesh_shape[0]: 1
mesh_rules[0][1].config_modifiers[0].mesh_shape[1]: 1
mesh_rules[0][1].config_modifiers[0].mesh_shape[2]: 1
mesh_rules[0][1].config_modifiers[0].mesh_shape[3]: -1
mesh_rules[0][1].config_modifiers[0].mesh_shape[4]: 1
mesh_rules[0][1].config_modifiers[0].mesh_shape[5]: 4
mesh_rules[0][1].config_modifiers[1].klass: 'axlearn.common.trainer_config_modifier.ModuleConfigModifier'
mesh_rules[0][1].config_modifiers[1].modification.klass: 'axlearn.common.attention.StackedTransformerLayer'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.activation: 'nn.relu'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.dropout.klass: 'axlearn.common.layers.Dropout'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.klass: 'axlearn.common.attention.TransformerFeedForwardLayer'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear1.bias: True
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear1.klass: 'axlearn.common.layers.Linear'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear1.param_partition_spec[0]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear1.param_partition_spec[1]: 'model'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear2.bias: True
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear2.klass: 'axlearn.common.layers.Linear'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear2.param_partition_spec[0]: 'model'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.linear2.param_partition_spec[1]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.norm.eps: 1e-08
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.norm.forward_dtype: 'jax.numpy.float32'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.norm.klass: 'axlearn.common.layers.LayerNorm'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.residual_weight: 1.0
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.stochastic_depth.mode: 'row'
mesh_rules[0][1].config_modifiers[1].modification.layer.feed_forward.structure: 'prenorm'
mesh_rules[0][1].config_modifiers[1].modification.layer.klass: 'axlearn.common.attention.TransformerLayer'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.dropout.klass: 'axlearn.common.layers.Dropout'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.klass: 'axlearn.common.attention.QKVLinear'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.layer.bias: True
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.layer.klass: 'axlearn.common.attention.MultiheadInputLinear'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.layer.param_partition_spec[0]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.layer.param_partition_spec[1]: 'model'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.input_linear.layer.param_partition_spec[2]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.key_scale.klass: 'axlearn.common.attention.ScaleKey'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.klass: 'axlearn.common.attention.MultiheadAttention'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.output_linear.bias: True
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.output_linear.klass: 'axlearn.common.attention.MultiheadOutputLinear'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.output_linear.param_partition_spec[0]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.output_linear.param_partition_spec[1]: 'model'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.output_linear.param_partition_spec[2]: None
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.attention.query_scale.klass: 'axlearn.common.attention.ScaleQuery'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.dropout.klass: 'axlearn.common.layers.Dropout'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.klass: 'axlearn.common.attention.TransformerAttentionLayer'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.norm.eps: 1e-08
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.norm.forward_dtype: 'jax.numpy.float32'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.norm.klass: 'axlearn.common.layers.LayerNorm'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.stochastic_depth.mode: 'row'
mesh_rules[0][1].config_modifiers[1].modification.layer.self_attention.structure: 'prenorm'
mesh_rules[0][1].config_modifiers[1].target_config: 'model.decoder.transformer'
mesh_rules[0][1].config_modifiers[2].klass: 'axlearn.common.trainer_config_modifier.PartitionSpecModifier'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['param_partition_spec'][0]: 'model'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['param_partition_spec'][1][0]: 'expert'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['param_partition_spec'][1][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['param_partition_spec'][1][2]: 'seq'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['input_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['input_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['input_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['output_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['output_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['output_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['output_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['embedding_partition_spec'][0]: 'model'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.emb.token_emb']['embedding_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['input_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['input_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['input_partition_spec'][1]: 'model'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['input_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['output_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['output_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['output_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.self_attention.norm']['output_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['input_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['input_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['input_partition_spec'][1]: 'model'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['input_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['output_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['output_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['output_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.norm']['output_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['input_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['input_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['input_partition_spec'][1]: 'model'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['input_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['output_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['output_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['output_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.output_norm']['output_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.linear2']['output_partition_spec'][0][0]: 'data'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.linear2']['output_partition_spec'][0][1]: 'fsdp'
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.linear2']['output_partition_spec'][1]: None
mesh_rules[0][1].config_modifiers[2].partition_specs['model.decoder.transformer.layer.feed_forward.linear2']['output_partition_spec'][2]: None
mesh_rules[0][1].config_modifiers[3].grad_acc_steps: 4
mesh_rules[0][1].config_modifiers[3].klass: 'axlearn.common.trainer_config_modifier.GradientAccumulationModifier'
mesh_rules[0][1].config_modifiers[3].metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
mesh_rules[0][1].klass: 'axlearn.common.trainer_config_modifier.ChainConfigModifier'
mesh_shape[0]: 1
mesh_shape[1]: -1
mesh_shape[2]: 1
mesh_shape[3]: 8
mesh_shape[4]: 1
mesh_shape[5]: 1
model.batch_axis_names: None
model.decoder.attention_mask: None
model.decoder.decoding.klass: 'axlearn.common.decoder.DecodingLayer'
model.decoder.dim: 3072
model.decoder.dropout_rate: 0.0
model.decoder.emb.dropout.klass: 'axlearn.common.layers.Dropout'
model.decoder.emb.klass: 'axlearn.common.embedding.TransformerTextEmbeddings'
model.decoder.emb.token_emb.klass: 'axlearn.common.layers.Embedding'
model.decoder.emb.token_emb.param_init.init_by_param_name['.*weight$'].distribution: 'normal'
model.decoder.emb.token_emb.param_init.init_by_param_name['.*weight$'].fan: 'fan_out'
model.decoder.emb.token_emb.param_init.init_by_param_name['.*weight$'].klass: 'axlearn.common.param_init.WeightInitializer'
model.decoder.emb.token_emb.param_init.init_by_param_name['.*weight$'].scale: 1.0
model.decoder.emb.token_emb.param_init.klass: 'axlearn.common.param_init.DefaultInitializer'
model.decoder.emb.token_emb.param_partition_spec[0]: None
model.decoder.emb.token_emb.param_partition_spec[1]: 'model'
model.decoder.eos_token_id: 128001
model.decoder.klass: 'axlearn.common.decoder.Decoder'
model.decoder.logits_partition_spec[0][0]: 'data'
model.decoder.logits_partition_spec[0][1]: 'expert'
model.decoder.logits_partition_spec[0][2]: 'fsdp'
model.decoder.logits_partition_spec[1]: 'seq'
model.decoder.logits_partition_spec[2]: 'model'
model.decoder.output_dropout.klass: 'axlearn.common.layers.Dropout'
model.decoder.output_norm.eps: 1e-05
model.decoder.output_norm.forward_dtype: None
model.decoder.output_norm.klass: 'axlearn.common.layers.RMSNorm'
model.decoder.pad_token_id: 128004
model.decoder.transformer.klass: 'axlearn.common.attention.RepeatedTransformerLayer'
model.decoder.transformer.layer.feed_forward.activation[0]: 'nn.silu'
model.decoder.transformer.layer.feed_forward.activation[1]: 'linear'
model.decoder.transformer.layer.feed_forward.dropout.klass: 'axlearn.common.layers.Dropout'
model.decoder.transformer.layer.feed_forward.hidden_dim: 8192
model.decoder.transformer.layer.feed_forward.klass: 'axlearn.common.attention.TransformerFeedForwardLayer'
model.decoder.transformer.layer.feed_forward.linear1.bias: False
model.decoder.transformer.layer.feed_forward.linear1.klass: 'axlearn.common.layers.Linear'
model.decoder.transformer.layer.feed_forward.linear1.output_partition_spec[0][0]: 'data'
model.decoder.transformer.layer.feed_forward.linear1.output_partition_spec[0][1]: 'expert'
model.decoder.transformer.layer.feed_forward.linear1.output_partition_spec[0][2]: 'fsdp'
model.decoder.transformer.layer.feed_forward.linear1.output_partition_spec[1]: 'seq'
model.decoder.transformer.layer.feed_forward.linear1.output_partition_spec[2]: 'model'
model.decoder.transformer.layer.feed_forward.linear1.param_partition_spec[0][0]: 'expert'
model.decoder.transformer.layer.feed_forward.linear1.param_partition_spec[0][1]: 'fsdp'
model.decoder.transformer.layer.feed_forward.linear1.param_partition_spec[0][2]: 'seq'
model.decoder.transformer.layer.feed_forward.linear1.param_partition_spec[1]: 'model'
model.decoder.transformer.layer.feed_forward.linear2.bias: False
model.decoder.transformer.layer.feed_forward.linear2.klass: 'axlearn.common.layers.Linear'
model.decoder.transformer.layer.feed_forward.linear2.output_partition_spec[0][0]: 'data'
model.decoder.transformer.layer.feed_forward.linear2.output_partition_spec[0][1]: 'expert'
model.decoder.transformer.layer.feed_forward.linear2.output_partition_spec[0][2]: 'fsdp'
model.decoder.transformer.layer.feed_forward.linear2.output_partition_spec[1]: 'seq'
model.decoder.transformer.layer.feed_forward.linear2.output_partition_spec[2]: 'model'
model.decoder.transformer.layer.feed_forward.linear2.param_partition_spec[0]: 'model'
model.decoder.transformer.layer.feed_forward.linear2.param_partition_spec[1][0]: 'expert'
model.decoder.transformer.layer.feed_forward.linear2.param_partition_spec[1][1]: 'fsdp'
model.decoder.transformer.layer.feed_forward.linear2.param_partition_spec[1][2]: 'seq'
model.decoder.transformer.layer.feed_forward.norm.eps: 1e-05
model.decoder.transformer.layer.feed_forward.norm.forward_dtype: None
model.decoder.transformer.layer.feed_forward.norm.klass: 'axlearn.common.layers.RMSNorm'
model.decoder.transformer.layer.feed_forward.residual_weight: 1.0
model.decoder.transformer.layer.feed_forward.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
model.decoder.transformer.layer.feed_forward.stochastic_depth.mode: 'row'
model.decoder.transformer.layer.feed_forward.structure: 'prenorm'
model.decoder.transformer.layer.klass: 'axlearn.common.attention.TransformerLayer'
model.decoder.transformer.layer.remat_spec['prevent_cse']: False
model.decoder.transformer.layer.remat_spec['policy'].fn: 'axlearn.common.attention._save_and_offload_only_these_names_regex'
model.decoder.transformer.layer.remat_spec['policy'].names_which_can_be_offloaded: None
model.decoder.transformer.layer.remat_spec['policy'].names_which_can_be_saved: '.*([qkvo]_proj|context)'
model.decoder.transformer.layer.remat_spec['policy'].offload_dst: 'pinned_host'
model.decoder.transformer.layer.remat_spec['policy'].offload_src: 'device'
model.decoder.transformer.layer.self_attention.attention.causal: True
model.decoder.transformer.layer.self_attention.attention.dropout.klass: 'axlearn.common.layers.Dropout'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.klass: 'axlearn.common.attention.FusedGroupedQKVLinear'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.bias: False
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.klass: 'axlearn.common.attention.MultiheadInputLinear'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.param_partition_spec[0][0]: 'expert'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.param_partition_spec[0][1]: 'fsdp'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.param_partition_spec[0][2]: 'seq'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.param_partition_spec[1]: 'model'
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.layer.param_partition_spec[2]: None
model.decoder.transformer.layer.self_attention.attention.input_linear.input_linear.num_kv_heads: 8
model.decoder.transformer.layer.self_attention.attention.input_linear.klass: 'axlearn.common.attention.RoFormerQKVLinear'
model.decoder.transformer.layer.self_attention.attention.input_linear.rope_pos_emb_layer.klass: 'axlearn.common.attention.RoFormerSinusoidalPositionalEmbedding'
model.decoder.transformer.layer.self_attention.attention.input_linear.rope_pos_emb_layer.theta: 500000.0
model.decoder.transformer.layer.self_attention.attention.input_linear.rotary_value: False
model.decoder.transformer.layer.self_attention.attention.key_scale.klass: 'axlearn.common.attention.ScaleKey'
model.decoder.transformer.layer.self_attention.attention.klass: 'axlearn.common.flash_attention.layer.FlashAttention'
model.decoder.transformer.layer.self_attention.attention.kv_cache.cache_dtype: 'jax.numpy.bfloat16'
model.decoder.transformer.layer.self_attention.attention.kv_cache.klass: 'axlearn.common.kv_cache.kv_cache.KVCache'
model.decoder.transformer.layer.self_attention.attention.mha_dim_to_partition_spec['btnh']: PartitionSpec(('data', 'expert', 'fsdp'), None, ('seq', 'model'), None)
model.decoder.transformer.layer.self_attention.attention.mha_dim_to_partition_spec['bsnh']: PartitionSpec(('data', 'expert', 'fsdp'), None, ('seq', 'model'), None)
model.decoder.transformer.layer.self_attention.attention.mha_dim_to_partition_spec['bnts']: PartitionSpec(('data', 'expert', 'fsdp'), None, None, None)
model.decoder.transformer.layer.self_attention.attention.num_heads: 24
model.decoder.transformer.layer.self_attention.attention.output_dim_to_partition_spec['btnh']: PartitionSpec(('data', 'expert', 'fsdp'), 'seq', 'model', None)
model.decoder.transformer.layer.self_attention.attention.output_dim_to_partition_spec['bnts']: PartitionSpec(('data', 'expert', 'fsdp'), 'model', 'seq', None)
model.decoder.transformer.layer.self_attention.attention.output_linear.bias: False
model.decoder.transformer.layer.self_attention.attention.output_linear.klass: 'axlearn.common.attention.MultiheadOutputLinear'
model.decoder.transformer.layer.self_attention.attention.output_linear.param_partition_spec[0][0]: 'expert'
model.decoder.transformer.layer.self_attention.attention.output_linear.param_partition_spec[0][1]: 'fsdp'
model.decoder.transformer.layer.self_attention.attention.output_linear.param_partition_spec[0][2]: 'seq'
model.decoder.transformer.layer.self_attention.attention.output_linear.param_partition_spec[1]: 'model'
model.decoder.transformer.layer.self_attention.attention.output_linear.param_partition_spec[2]: None
model.decoder.transformer.layer.self_attention.attention.query_scale.klass: 'axlearn.common.attention.ScaleQuery'
model.decoder.transformer.layer.self_attention.attention.tpu_block_size: 512
model.decoder.transformer.layer.self_attention.dropout.klass: 'axlearn.common.layers.Dropout'
model.decoder.transformer.layer.self_attention.klass: 'axlearn.common.attention.TransformerAttentionLayer'
model.decoder.transformer.layer.self_attention.norm.eps: 1e-05
model.decoder.transformer.layer.self_attention.norm.forward_dtype: None
model.decoder.transformer.layer.self_attention.norm.klass: 'axlearn.common.layers.RMSNorm'
model.decoder.transformer.layer.self_attention.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
model.decoder.transformer.layer.self_attention.stochastic_depth.mode: 'row'
model.decoder.transformer.layer.self_attention.structure: 'prenorm'
model.decoder.transformer.num_layers: 28
model.decoder.transformer.repeat.drop_output.fn: 'axlearn.common.repeat._drop_by_regex'
model.decoder.transformer.repeat.drop_output.rules[0]: 'module_outputs.*'
model.decoder.transformer.repeat.klass: 'axlearn.common.attention._TransformerRepeat'
model.decoder.vocab_size: 128256
model.dtype: 'jax.numpy.float32'
model.klass: 'axlearn.common.causal_lm.Model'
model.metrics.klass: 'axlearn.common.causal_lm.CompositeLossMetrics'
model.metrics.metrics['lm'].klass: 'axlearn.common.causal_lm.CrossEntropyLossMetrics'
model.metrics.metrics['aux'].klass: 'axlearn.common.causal_lm.AuxLossMetrics'
model.param_init.init_by_param_name['.*weight$'].distribution: 'normal'
model.param_init.init_by_param_name['.*weight$'].fan: 'fan_in'
model.param_init.init_by_param_name['.*weight$'].klass: 'axlearn.common.param_init.WeightInitializer'
model.param_init.init_by_param_name['.*weight$'].scale: 1.0
model.param_init.klass: 'axlearn.common.param_init.DefaultInitializer'
name: 'gpt_trainer'
prune_empty_state_updates: True
save_input_iterator: False
start_trace_process_indices[0]: 0
summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
summary_writer.max_queue: 1000
summary_writer.write_every_n_steps: 100
train_dtype: 'jax.numpy.bfloat16'