====================weight_decay_scale root.optimizer====================
decoder/emb/token_emb/weight: 1
decoder/output_norm/scale: 1
decoder/transformer/repeat/layer/layer0/feed_forward/linear1_0/weight: 1
decoder/transformer/repeat/layer/layer0/feed_forward/linear1_1/weight: 1
decoder/transformer/repeat/layer/layer0/feed_forward/linear2/weight: 1
decoder/transformer/repeat/layer/layer0/feed_forward/norm/scale: 1
decoder/transformer/repeat/layer/layer0/self_attention/attention/i_proj/i_proj/qkv_proj/weight: 1
decoder/transformer/repeat/layer/layer0/self_attention/attention/o_proj/weight: 1
decoder/transformer/repeat/layer/layer0/self_attention/attention/scale_key/norm/scale: 1
decoder/transformer/repeat/layer/layer0/self_attention/attention/scale_query/norm/scale: 1
decoder/transformer/repeat/layer/layer0/self_attention/norm/scale: 1
decoder/transformer/repeat/layer/layer1/feed_forward/gate_weight: 1
decoder/transformer/repeat/layer/layer1/feed_forward/norm/scale: 1
decoder/transformer/repeat/layer/layer1/feed_forward/wi_0_weight: 1
decoder/transformer/repeat/layer/layer1/feed_forward/wi_1_weight: 1
decoder/transformer/repeat/layer/layer1/feed_forward/wo_weight: 1
decoder/transformer/repeat/layer/layer1/self_attention/attention/i_proj/i_proj/qkv_proj/weight: 1
decoder/transformer/repeat/layer/layer1/self_attention/attention/o_proj/weight: 1
decoder/transformer/repeat/layer/layer1/self_attention/attention/scale_key/norm/scale: 1
decoder/transformer/repeat/layer/layer1/self_attention/attention/scale_query/norm/scale: 1
decoder/transformer/repeat/layer/layer1/self_attention/norm/scale: 1
