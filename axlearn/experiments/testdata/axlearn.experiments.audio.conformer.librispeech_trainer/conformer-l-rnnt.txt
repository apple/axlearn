batch_axis_names: 'data'
checkpointer.gc_loop_interval_seconds: 60
checkpointer.keep_every_n_steps: 100
checkpointer.keep_last_n: 1
checkpointer.klass: 'axlearn.common.checkpointer.Checkpointer'
checkpointer.save_policy.fn: 'axlearn.common.checkpointer.every_n_steps_policy'
checkpointer.save_policy.min_step: 1
checkpointer.save_policy.n: 100
checkpointer.storage.klass: 'axlearn.common.checkpointer.TensorStoreStateStorage'
checkpointer.storage.timeout_secs: 3600
evalers['eval_train'].eval_dtype: 'jax.numpy.float32'
evalers['eval_train'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['eval_train'].eval_policy.min_step: 1
evalers['eval_train'].eval_policy.n: 1000
evalers['eval_train'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['eval_train'].input.batcher.global_batch_size: 512
evalers['eval_train'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['eval_train'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['eval_train'].input.processor.eos_id: 2
evalers['eval_train'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['eval_train'].input.processor.max_source_len: 576000
evalers['eval_train'].input.processor.max_target_len: 200
evalers['eval_train'].input.processor.vocab_cfg.extra_ids: 0
evalers['eval_train'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['eval_train'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['eval_train'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['eval_train'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['eval_train'].input.source.download: False
evalers['eval_train'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['eval_train'].input.source.split: 'train_clean100[:512]+train_clean360[:512]+train_other500[:512]'
evalers['eval_train'].input.source.train_shuffle_buffer_size: 0
evalers['eval_train'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['eval_train'].metric_calculator.klass: 'axlearn.common.evaler.ModelSummaryAccumulator'
evalers['eval_train'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['eval_train'].metric_calculator.model_method: 'forward'
evalers['eval_train'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['eval_train'].summary_writer.write_every_n_steps: 1
evalers['eval_dev_clean'].eval_dtype: 'jax.numpy.float32'
evalers['eval_dev_clean'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['eval_dev_clean'].eval_policy.min_step: 1
evalers['eval_dev_clean'].eval_policy.n: 1000
evalers['eval_dev_clean'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['eval_dev_clean'].input.batcher.global_batch_size: 512
evalers['eval_dev_clean'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['eval_dev_clean'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['eval_dev_clean'].input.processor.eos_id: 2
evalers['eval_dev_clean'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['eval_dev_clean'].input.processor.max_source_len: 576000
evalers['eval_dev_clean'].input.processor.max_target_len: 200
evalers['eval_dev_clean'].input.processor.vocab_cfg.extra_ids: 0
evalers['eval_dev_clean'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['eval_dev_clean'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['eval_dev_clean'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['eval_dev_clean'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['eval_dev_clean'].input.source.download: False
evalers['eval_dev_clean'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['eval_dev_clean'].input.source.split: 'dev_clean'
evalers['eval_dev_clean'].input.source.train_shuffle_buffer_size: 0
evalers['eval_dev_clean'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['eval_dev_clean'].metric_calculator.klass: 'axlearn.common.evaler.ModelSummaryAccumulator'
evalers['eval_dev_clean'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['eval_dev_clean'].metric_calculator.model_method: 'forward'
evalers['eval_dev_clean'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['eval_dev_clean'].summary_writer.write_every_n_steps: 1
evalers['eval_dev_other'].eval_dtype: 'jax.numpy.float32'
evalers['eval_dev_other'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['eval_dev_other'].eval_policy.min_step: 1
evalers['eval_dev_other'].eval_policy.n: 1000
evalers['eval_dev_other'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['eval_dev_other'].input.batcher.global_batch_size: 512
evalers['eval_dev_other'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['eval_dev_other'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['eval_dev_other'].input.processor.eos_id: 2
evalers['eval_dev_other'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['eval_dev_other'].input.processor.max_source_len: 576000
evalers['eval_dev_other'].input.processor.max_target_len: 200
evalers['eval_dev_other'].input.processor.vocab_cfg.extra_ids: 0
evalers['eval_dev_other'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['eval_dev_other'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['eval_dev_other'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['eval_dev_other'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['eval_dev_other'].input.source.download: False
evalers['eval_dev_other'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['eval_dev_other'].input.source.split: 'dev_other'
evalers['eval_dev_other'].input.source.train_shuffle_buffer_size: 0
evalers['eval_dev_other'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['eval_dev_other'].metric_calculator.klass: 'axlearn.common.evaler.ModelSummaryAccumulator'
evalers['eval_dev_other'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['eval_dev_other'].metric_calculator.model_method: 'forward'
evalers['eval_dev_other'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['eval_dev_other'].summary_writer.write_every_n_steps: 1
evalers['decoder_dev_clean'].eval_dtype: 'jax.numpy.float32'
evalers['decoder_dev_clean'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['decoder_dev_clean'].eval_policy.min_step: 1
evalers['decoder_dev_clean'].eval_policy.n: 1000
evalers['decoder_dev_clean'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['decoder_dev_clean'].input.batcher.global_batch_size: 512
evalers['decoder_dev_clean'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['decoder_dev_clean'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['decoder_dev_clean'].input.processor.eos_id: 2
evalers['decoder_dev_clean'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['decoder_dev_clean'].input.processor.max_source_len: 576000
evalers['decoder_dev_clean'].input.processor.max_target_len: 200
evalers['decoder_dev_clean'].input.processor.vocab_cfg.extra_ids: 0
evalers['decoder_dev_clean'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_dev_clean'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['decoder_dev_clean'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_dev_clean'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['decoder_dev_clean'].input.source.download: False
evalers['decoder_dev_clean'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['decoder_dev_clean'].input.source.split: 'dev_clean'
evalers['decoder_dev_clean'].input.source.train_shuffle_buffer_size: 0
evalers['decoder_dev_clean'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['decoder_dev_clean'].metric_calculator.klass: 'axlearn.audio.evaler_asr.WordErrorRateMetricCalculator'
evalers['decoder_dev_clean'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['decoder_dev_clean'].metric_calculator.model_method: 'beam_search_decode'
evalers['decoder_dev_clean'].metric_calculator.model_method_kwargs['num_decodes']: 8
evalers['decoder_dev_clean'].metric_calculator.model_method_kwargs['max_decode_len']: 1000
evalers['decoder_dev_clean'].metric_calculator.scorer.fn: 'axlearn.audio.evaler_asr.<lambda>'
evalers['decoder_dev_clean'].metric_calculator.text_normalizer.fn: 'axlearn.audio.evaler_asr.normalize_text'
evalers['decoder_dev_clean'].metric_calculator.vocab.extra_ids: 0
evalers['decoder_dev_clean'].metric_calculator.vocab.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_dev_clean'].metric_calculator.vocab.reverse_extra_ids: True
evalers['decoder_dev_clean'].metric_calculator.vocab.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_dev_clean'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['decoder_dev_clean'].summary_writer.write_every_n_steps: 1
evalers['decoder_dev_other'].eval_dtype: 'jax.numpy.float32'
evalers['decoder_dev_other'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['decoder_dev_other'].eval_policy.min_step: 1
evalers['decoder_dev_other'].eval_policy.n: 1000
evalers['decoder_dev_other'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['decoder_dev_other'].input.batcher.global_batch_size: 512
evalers['decoder_dev_other'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['decoder_dev_other'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['decoder_dev_other'].input.processor.eos_id: 2
evalers['decoder_dev_other'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['decoder_dev_other'].input.processor.max_source_len: 576000
evalers['decoder_dev_other'].input.processor.max_target_len: 200
evalers['decoder_dev_other'].input.processor.vocab_cfg.extra_ids: 0
evalers['decoder_dev_other'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_dev_other'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['decoder_dev_other'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_dev_other'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['decoder_dev_other'].input.source.download: False
evalers['decoder_dev_other'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['decoder_dev_other'].input.source.split: 'dev_other'
evalers['decoder_dev_other'].input.source.train_shuffle_buffer_size: 0
evalers['decoder_dev_other'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['decoder_dev_other'].metric_calculator.klass: 'axlearn.audio.evaler_asr.WordErrorRateMetricCalculator'
evalers['decoder_dev_other'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['decoder_dev_other'].metric_calculator.model_method: 'beam_search_decode'
evalers['decoder_dev_other'].metric_calculator.model_method_kwargs['num_decodes']: 8
evalers['decoder_dev_other'].metric_calculator.model_method_kwargs['max_decode_len']: 1000
evalers['decoder_dev_other'].metric_calculator.scorer.fn: 'axlearn.audio.evaler_asr.<lambda>'
evalers['decoder_dev_other'].metric_calculator.text_normalizer.fn: 'axlearn.audio.evaler_asr.normalize_text'
evalers['decoder_dev_other'].metric_calculator.vocab.extra_ids: 0
evalers['decoder_dev_other'].metric_calculator.vocab.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_dev_other'].metric_calculator.vocab.reverse_extra_ids: True
evalers['decoder_dev_other'].metric_calculator.vocab.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_dev_other'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['decoder_dev_other'].summary_writer.write_every_n_steps: 1
evalers['decoder_test_clean'].eval_dtype: 'jax.numpy.float32'
evalers['decoder_test_clean'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['decoder_test_clean'].eval_policy.min_step: 1
evalers['decoder_test_clean'].eval_policy.n: 1000
evalers['decoder_test_clean'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['decoder_test_clean'].input.batcher.global_batch_size: 512
evalers['decoder_test_clean'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['decoder_test_clean'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['decoder_test_clean'].input.processor.eos_id: 2
evalers['decoder_test_clean'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['decoder_test_clean'].input.processor.max_source_len: 576000
evalers['decoder_test_clean'].input.processor.max_target_len: 200
evalers['decoder_test_clean'].input.processor.vocab_cfg.extra_ids: 0
evalers['decoder_test_clean'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_test_clean'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['decoder_test_clean'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_test_clean'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['decoder_test_clean'].input.source.download: False
evalers['decoder_test_clean'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['decoder_test_clean'].input.source.split: 'test_clean'
evalers['decoder_test_clean'].input.source.train_shuffle_buffer_size: 0
evalers['decoder_test_clean'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['decoder_test_clean'].metric_calculator.klass: 'axlearn.audio.evaler_asr.WordErrorRateMetricCalculator'
evalers['decoder_test_clean'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['decoder_test_clean'].metric_calculator.model_method: 'beam_search_decode'
evalers['decoder_test_clean'].metric_calculator.model_method_kwargs['num_decodes']: 8
evalers['decoder_test_clean'].metric_calculator.model_method_kwargs['max_decode_len']: 1000
evalers['decoder_test_clean'].metric_calculator.scorer.fn: 'axlearn.audio.evaler_asr.<lambda>'
evalers['decoder_test_clean'].metric_calculator.text_normalizer.fn: 'axlearn.audio.evaler_asr.normalize_text'
evalers['decoder_test_clean'].metric_calculator.vocab.extra_ids: 0
evalers['decoder_test_clean'].metric_calculator.vocab.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_test_clean'].metric_calculator.vocab.reverse_extra_ids: True
evalers['decoder_test_clean'].metric_calculator.vocab.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_test_clean'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['decoder_test_clean'].summary_writer.write_every_n_steps: 1
evalers['decoder_test_other'].eval_dtype: 'jax.numpy.float32'
evalers['decoder_test_other'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['decoder_test_other'].eval_policy.min_step: 1
evalers['decoder_test_other'].eval_policy.n: 1000
evalers['decoder_test_other'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['decoder_test_other'].input.batcher.global_batch_size: 512
evalers['decoder_test_other'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['decoder_test_other'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['decoder_test_other'].input.processor.eos_id: 2
evalers['decoder_test_other'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['decoder_test_other'].input.processor.max_source_len: 576000
evalers['decoder_test_other'].input.processor.max_target_len: 200
evalers['decoder_test_other'].input.processor.vocab_cfg.extra_ids: 0
evalers['decoder_test_other'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_test_other'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['decoder_test_other'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_test_other'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['decoder_test_other'].input.source.download: False
evalers['decoder_test_other'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['decoder_test_other'].input.source.split: 'test_other'
evalers['decoder_test_other'].input.source.train_shuffle_buffer_size: 0
evalers['decoder_test_other'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['decoder_test_other'].metric_calculator.klass: 'axlearn.audio.evaler_asr.WordErrorRateMetricCalculator'
evalers['decoder_test_other'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['decoder_test_other'].metric_calculator.model_method: 'beam_search_decode'
evalers['decoder_test_other'].metric_calculator.model_method_kwargs['num_decodes']: 8
evalers['decoder_test_other'].metric_calculator.model_method_kwargs['max_decode_len']: 1000
evalers['decoder_test_other'].metric_calculator.scorer.fn: 'axlearn.audio.evaler_asr.<lambda>'
evalers['decoder_test_other'].metric_calculator.text_normalizer.fn: 'axlearn.audio.evaler_asr.normalize_text'
evalers['decoder_test_other'].metric_calculator.vocab.extra_ids: 0
evalers['decoder_test_other'].metric_calculator.vocab.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_test_other'].metric_calculator.vocab.reverse_extra_ids: True
evalers['decoder_test_other'].metric_calculator.vocab.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_test_other'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['decoder_test_other'].summary_writer.write_every_n_steps: 1
evalers['decoder_train'].eval_dtype: 'jax.numpy.float32'
evalers['decoder_train'].eval_policy.fn: 'axlearn.common.evaler.every_n_steps_policy'
evalers['decoder_train'].eval_policy.min_step: 1
evalers['decoder_train'].eval_policy.n: 1000
evalers['decoder_train'].input.batcher.fn: 'axlearn.common.input_tf_data.batch'
evalers['decoder_train'].input.batcher.global_batch_size: 512
evalers['decoder_train'].input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
evalers['decoder_train'].input.klass: 'axlearn.common.input_tf_data.Input'
evalers['decoder_train'].input.processor.eos_id: 2
evalers['decoder_train'].input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
evalers['decoder_train'].input.processor.max_source_len: 576000
evalers['decoder_train'].input.processor.max_target_len: 200
evalers['decoder_train'].input.processor.vocab_cfg.extra_ids: 0
evalers['decoder_train'].input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_train'].input.processor.vocab_cfg.reverse_extra_ids: True
evalers['decoder_train'].input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_train'].input.source.dataset_name: 'librispeech:2.1.0'
evalers['decoder_train'].input.source.download: False
evalers['decoder_train'].input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
evalers['decoder_train'].input.source.split: 'train_clean100[:512]+train_clean360[:512]+train_other500[:512]'
evalers['decoder_train'].input.source.train_shuffle_buffer_size: 0
evalers['decoder_train'].klass: 'axlearn.common.evaler.SpmdEvaler'
evalers['decoder_train'].metric_calculator.klass: 'axlearn.audio.evaler_asr.WordErrorRateMetricCalculator'
evalers['decoder_train'].metric_calculator.metric_accumulator.klass: 'axlearn.common.metrics.MetricAccumulator'
evalers['decoder_train'].metric_calculator.model_method: 'beam_search_decode'
evalers['decoder_train'].metric_calculator.model_method_kwargs['num_decodes']: 8
evalers['decoder_train'].metric_calculator.model_method_kwargs['max_decode_len']: 1000
evalers['decoder_train'].metric_calculator.scorer.fn: 'axlearn.audio.evaler_asr.<lambda>'
evalers['decoder_train'].metric_calculator.text_normalizer.fn: 'axlearn.audio.evaler_asr.normalize_text'
evalers['decoder_train'].metric_calculator.vocab.extra_ids: 0
evalers['decoder_train'].metric_calculator.vocab.klass: 'seqio.vocabularies.SentencePieceVocabulary'
evalers['decoder_train'].metric_calculator.vocab.reverse_extra_ids: True
evalers['decoder_train'].metric_calculator.vocab.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
evalers['decoder_train'].summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
evalers['decoder_train'].summary_writer.write_every_n_steps: 1
input.batcher.fn: 'axlearn.common.input_tf_data.batch'
input.batcher.global_batch_size: 2048
input.batcher.pad_example_fn: 'axlearn.audio.input_asr.pad_example_fn'
input.klass: 'axlearn.common.input_tf_data.Input'
input.processor.eos_id: 2
input.processor.fn: 'axlearn.experiments.audio.conformer.common.asr_input'
input.processor.max_source_len: 480000
input.processor.max_target_len: 200
input.processor.vocab_cfg.extra_ids: 0
input.processor.vocab_cfg.klass: 'seqio.vocabularies.SentencePieceVocabulary'
input.processor.vocab_cfg.reverse_extra_ids: True
input.processor.vocab_cfg.sentencepiece_model_file: '$DATA_DIR/tokenizers/sentencepiece/librispeech_bpe_1024.model'
input.source.dataset_name: 'librispeech:2.1.0'
input.source.download: False
input.source.fn: 'axlearn.common.input_tf_data.tfds_dataset'
input.source.split: 'train_clean100+train_clean360+train_other500'
input.source.train_shuffle_buffer_size: 16384
klass: 'axlearn.common.trainer.SpmdTrainer'
learner.ema.decay: 0.9999
learner.ema.fn: 'axlearn.common.optimizers.param_ema'
learner.enable_per_variable_summaries: False
learner.klass: 'axlearn.common.learner.Learner'
learner.optimizer.args[0].eps: 1e-08
learner.optimizer.args[0].fn: 'axlearn.common.optimizers.clip_by_global_norm'
learner.optimizer.args[0].max_norm: 1.0
learner.optimizer.args[1].b1: 0.9
learner.optimizer.args[1].b2: 0.98
learner.optimizer.args[1].eps: 1e-09
learner.optimizer.args[1].fn: 'axlearn.common.optimizers.adam_optimizer'
learner.optimizer.args[1].l2_regularizer_per_param_scale.default_scale: 1.0
learner.optimizer.args[1].l2_regularizer_per_param_scale.description: 'l2_regularizer_scale'
learner.optimizer.args[1].l2_regularizer_per_param_scale.fn: 'axlearn.common.optimizers.per_param_scale_by_path'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[0][0]: '.*norm/.*'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[0][1]: 0
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[1][0]: '(.*/)?bias'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[1][1]: 0
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[2][0]: '(.*/)?scale'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[2][1]: 0
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[3][0]: '(.*/)?per_dim_scale/param'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[3][1]: 0
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[4][0]: '(.*/)?moving_mean'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[4][1]: 0
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[5][0]: '(.*/)?moving_variance'
learner.optimizer.args[1].l2_regularizer_per_param_scale.scale_by_path[5][1]: 0
learner.optimizer.args[1].l2_regularizer_weight: 1e-06
learner.optimizer.args[1].learning_rate.decay_power: -0.5
learner.optimizer.args[1].learning_rate.fn: 'axlearn.common.schedule.adafactor'
learner.optimizer.args[1].learning_rate.scale: 0.22097
learner.optimizer.args[1].learning_rate.step_offset: 1
learner.optimizer.args[1].learning_rate.warmup_steps: 10000
learner.optimizer.fn: 'axlearn.common.optimizers.chain'
max_step: 500000
model.decoder.am_proj.bias: True
model.decoder.am_proj.klass: 'axlearn.common.layers.Linear'
model.decoder.am_proj.param_partition_spec[0]: None
model.decoder.am_proj.param_partition_spec[1]: None
model.decoder.blank_id: 0
model.decoder.bos_id: 1
model.decoder.eos_id: 2
model.decoder.joint_dim: 640
model.decoder.klass: 'axlearn.audio.decoder_asr.TransducerDecoderModel'
model.decoder.lm_dim: 640
model.decoder.lm_proj.bias: True
model.decoder.lm_proj.klass: 'axlearn.common.layers.Linear'
model.decoder.lm_proj.param_partition_spec[0]: None
model.decoder.lm_proj.param_partition_spec[1]: None
model.decoder.prediction_network.emb_dim: 128
model.decoder.prediction_network.embedding.klass: 'axlearn.common.layers.Embedding'
model.decoder.prediction_network.embedding.param_init.init_by_param_name['.*weight$'].distribution: 'uniform'
model.decoder.prediction_network.embedding.param_init.init_by_param_name['.*weight$'].fan: None
model.decoder.prediction_network.embedding.param_init.init_by_param_name['.*weight$'].klass: 'axlearn.common.param_init.WeightInitializer'
model.decoder.prediction_network.embedding.param_init.init_by_param_name['.*weight$'].scale: 1.0
model.decoder.prediction_network.embedding.param_init.klass: 'axlearn.common.param_init.DefaultInitializer'
model.decoder.prediction_network.embedding.param_partition_spec[0]: None
model.decoder.prediction_network.embedding.param_partition_spec[1]: 'model'
model.decoder.prediction_network.klass: 'axlearn.audio.decoder_asr.RNNPredictionNetwork'
model.decoder.prediction_network.param_noise.klass: 'axlearn.common.layers.VariationalNoise'
model.decoder.prediction_network.param_noise.vn_std: 0.075
model.decoder.prediction_network.rnn_cell.input_proj.bias: True
model.decoder.prediction_network.rnn_cell.input_proj.klass: 'axlearn.common.layers.MultiLinear'
model.decoder.prediction_network.rnn_cell.input_proj.param_partition_spec[0]: None
model.decoder.prediction_network.rnn_cell.input_proj.param_partition_spec[1]: None
model.decoder.prediction_network.rnn_cell.input_proj.param_partition_spec[2]: 'model'
model.decoder.prediction_network.rnn_cell.klass: 'axlearn.common.rnn.LSTMCell'
model.decoder.prediction_network.rnn_cell.max_cell_value: 10.0
model.decoder.prediction_network.rnn_cell.output_proj: None
model.decoder.prediction_network.rnn_cell.param_init.init_by_param_name['.*weight$'].distribution: 'uniform'
model.decoder.prediction_network.rnn_cell.param_init.init_by_param_name['.*weight$'].fan: None
model.decoder.prediction_network.rnn_cell.param_init.init_by_param_name['.*weight$'].klass: 'axlearn.common.param_init.WeightInitializer'
model.decoder.prediction_network.rnn_cell.param_init.init_by_param_name['.*weight$'].scale: 0.1
model.decoder.prediction_network.rnn_cell.param_init.klass: 'axlearn.common.param_init.DefaultInitializer'
model.decoder.transducer.activation_fn: 'nn.tanh'
model.decoder.transducer.klass: 'axlearn.common.transducer.Transducer'
model.decoder.transducer.logits_to_log_probs.blank_logit_bias: 0
model.decoder.transducer.logits_to_log_probs.fn: 'axlearn.common.transducer.classic_logits_to_log_probs'
model.decoder.transducer.proj.bias: True
model.decoder.transducer.proj.klass: 'axlearn.common.layers.Linear'
model.decoder.transducer.proj.param_partition_spec[0]: None
model.decoder.transducer.proj.param_partition_spec[1]: None
model.decoder.vocab_size: 1024
model.dtype: 'jax.numpy.float32'
model.encoder.context.context.klass: 'axlearn.common.conformer.RepeatedConformerLayer'
model.encoder.context.context.layer.ff_end.activation: 'nn.silu'
model.encoder.context.context.layer.ff_end.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.context.layer.ff_end.dropout.rate: 0.1
model.encoder.context.context.layer.ff_end.hidden_dim.fn: 'axlearn.common.attention.scale_fn'
model.encoder.context.context.layer.ff_end.hidden_dim.scale: 4
model.encoder.context.context.layer.ff_end.klass: 'axlearn.common.attention.TransformerFeedForwardLayer'
model.encoder.context.context.layer.ff_end.linear1.bias: True
model.encoder.context.context.layer.ff_end.linear1.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.ff_end.linear1.param_partition_spec[0]: None
model.encoder.context.context.layer.ff_end.linear1.param_partition_spec[1]: 'model'
model.encoder.context.context.layer.ff_end.linear2.bias: True
model.encoder.context.context.layer.ff_end.linear2.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.ff_end.linear2.param_partition_spec[0]: 'model'
model.encoder.context.context.layer.ff_end.linear2.param_partition_spec[1]: None
model.encoder.context.context.layer.ff_end.norm.eps: 1e-08
model.encoder.context.context.layer.ff_end.norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.ff_end.norm.klass: 'axlearn.common.layers.LayerNorm'
model.encoder.context.context.layer.ff_end.residual_weight: 0.5
model.encoder.context.context.layer.ff_end.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
model.encoder.context.context.layer.ff_end.stochastic_depth.mode: 'row'
model.encoder.context.context.layer.ff_end.structure: 'prenorm'
model.encoder.context.context.layer.ff_start.activation: 'nn.silu'
model.encoder.context.context.layer.ff_start.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.context.layer.ff_start.dropout.rate: 0.1
model.encoder.context.context.layer.ff_start.hidden_dim.fn: 'axlearn.common.attention.scale_fn'
model.encoder.context.context.layer.ff_start.hidden_dim.scale: 4
model.encoder.context.context.layer.ff_start.klass: 'axlearn.common.attention.TransformerFeedForwardLayer'
model.encoder.context.context.layer.ff_start.linear1.bias: True
model.encoder.context.context.layer.ff_start.linear1.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.ff_start.linear1.param_partition_spec[0]: None
model.encoder.context.context.layer.ff_start.linear1.param_partition_spec[1]: 'model'
model.encoder.context.context.layer.ff_start.linear2.bias: True
model.encoder.context.context.layer.ff_start.linear2.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.ff_start.linear2.param_partition_spec[0]: 'model'
model.encoder.context.context.layer.ff_start.linear2.param_partition_spec[1]: None
model.encoder.context.context.layer.ff_start.norm.eps: 1e-08
model.encoder.context.context.layer.ff_start.norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.ff_start.norm.klass: 'axlearn.common.layers.LayerNorm'
model.encoder.context.context.layer.ff_start.residual_weight: 0.5
model.encoder.context.context.layer.ff_start.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
model.encoder.context.context.layer.ff_start.stochastic_depth.mode: 'row'
model.encoder.context.context.layer.ff_start.structure: 'prenorm'
model.encoder.context.context.layer.klass: 'axlearn.common.conformer.ConformerLayer'
model.encoder.context.context.layer.lconv.conv.bias: False
model.encoder.context.context.layer.lconv.conv.klass: 'axlearn.common.layers.DepthwiseConv1D'
model.encoder.context.context.layer.lconv.conv.padding: 'SAME'
model.encoder.context.context.layer.lconv.conv.param_partition_spec[0]: None
model.encoder.context.context.layer.lconv.conv.param_partition_spec[1]: None
model.encoder.context.context.layer.lconv.conv.param_partition_spec[2]: 'model'
model.encoder.context.context.layer.lconv.conv.strides: 1
model.encoder.context.context.layer.lconv.conv.window: 32
model.encoder.context.context.layer.lconv.conv_activation: 'nn.silu'
model.encoder.context.context.layer.lconv.conv_norm.decay: 0.999
model.encoder.context.context.layer.lconv.conv_norm.eps: 1e-08
model.encoder.context.context.layer.lconv.conv_norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.lconv.conv_norm.klass: 'axlearn.common.layers.BatchNorm'
model.encoder.context.context.layer.lconv.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.context.layer.lconv.dropout.rate: 0.1
model.encoder.context.context.layer.lconv.klass: 'axlearn.common.conformer.LConvLayer'
model.encoder.context.context.layer.lconv.linear1.bias: True
model.encoder.context.context.layer.lconv.linear1.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.lconv.linear1.param_partition_spec[0]: None
model.encoder.context.context.layer.lconv.linear1.param_partition_spec[1]: None
model.encoder.context.context.layer.lconv.linear1_activation[0]: 'linear'
model.encoder.context.context.layer.lconv.linear1_activation[1]: 'nn.sigmoid'
model.encoder.context.context.layer.lconv.linear1_norm.eps: 1e-08
model.encoder.context.context.layer.lconv.linear1_norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.lconv.linear1_norm.klass: 'axlearn.common.layers.LayerNorm'
model.encoder.context.context.layer.lconv.linear2.bias: True
model.encoder.context.context.layer.lconv.linear2.klass: 'axlearn.common.layers.Linear'
model.encoder.context.context.layer.lconv.linear2.param_partition_spec[0]: None
model.encoder.context.context.layer.lconv.linear2.param_partition_spec[1]: None
model.encoder.context.context.layer.neg_inf: -1000000000000000.0
model.encoder.context.context.layer.norm.eps: 1e-08
model.encoder.context.context.layer.norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.norm.klass: 'axlearn.common.layers.LayerNorm'
model.encoder.context.context.layer.self_attention.attention.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.context.layer.self_attention.attention.dropout.rate: 0.1
model.encoder.context.context.layer.self_attention.attention.input_linear.klass: 'axlearn.common.attention.FusedQKVLinear'
model.encoder.context.context.layer.self_attention.attention.input_linear.layer.bias: True
model.encoder.context.context.layer.self_attention.attention.input_linear.layer.klass: 'axlearn.common.attention.MultiheadInputLinear'
model.encoder.context.context.layer.self_attention.attention.input_linear.layer.param_partition_spec[0]: None
model.encoder.context.context.layer.self_attention.attention.input_linear.layer.param_partition_spec[1]: 'model'
model.encoder.context.context.layer.self_attention.attention.input_linear.layer.param_partition_spec[2]: None
model.encoder.context.context.layer.self_attention.attention.key_scale.klass: 'axlearn.common.attention.ScaleKey'
model.encoder.context.context.layer.self_attention.attention.klass: 'axlearn.common.attention.MultiheadAttentionXL'
model.encoder.context.context.layer.self_attention.attention.num_heads: 8
model.encoder.context.context.layer.self_attention.attention.output_linear.bias: True
model.encoder.context.context.layer.self_attention.attention.output_linear.klass: 'axlearn.common.attention.MultiheadOutputLinear'
model.encoder.context.context.layer.self_attention.attention.output_linear.param_partition_spec[0]: None
model.encoder.context.context.layer.self_attention.attention.output_linear.param_partition_spec[1]: 'model'
model.encoder.context.context.layer.self_attention.attention.output_linear.param_partition_spec[2]: None
model.encoder.context.context.layer.self_attention.attention.query_scale.klass: 'axlearn.common.attention.ScaleQuery'
model.encoder.context.context.layer.self_attention.attention.query_scale.per_dim_scale.klass: 'axlearn.common.attention.PerDimScale'
model.encoder.context.context.layer.self_attention.attention.query_scale.per_dim_scale.param_init.klass: 'axlearn.common.param_init.ConstantInitializer'
model.encoder.context.context.layer.self_attention.attention.query_scale.per_dim_scale.param_init.value: 0.0
model.encoder.context.context.layer.self_attention.attention.relative_pos_emb.klass: 'axlearn.common.attention.SinusoidalPositionalEmbedding'
model.encoder.context.context.layer.self_attention.attention.relative_pos_emb.max_timescale: 10000
model.encoder.context.context.layer.self_attention.attention.relative_pos_emb.min_timescale: 1
model.encoder.context.context.layer.self_attention.attention.relative_pos_linear.bias: False
model.encoder.context.context.layer.self_attention.attention.relative_pos_linear.klass: 'axlearn.common.attention.MultiheadRelativePositionLinear'
model.encoder.context.context.layer.self_attention.attention.relative_pos_linear.param_partition_spec[0]: None
model.encoder.context.context.layer.self_attention.attention.relative_pos_linear.param_partition_spec[1]: 'model'
model.encoder.context.context.layer.self_attention.attention.relative_pos_linear.param_partition_spec[2]: None
model.encoder.context.context.layer.self_attention.attention.scale_position: <ScalePosition.QUERY: 1>
model.encoder.context.context.layer.self_attention.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.context.layer.self_attention.dropout.rate: 0.1
model.encoder.context.context.layer.self_attention.klass: 'axlearn.common.attention.TransformerAttentionLayer'
model.encoder.context.context.layer.self_attention.norm.eps: 1e-08
model.encoder.context.context.layer.self_attention.norm.forward_dtype: 'jax.numpy.float32'
model.encoder.context.context.layer.self_attention.norm.klass: 'axlearn.common.layers.LayerNorm'
model.encoder.context.context.layer.self_attention.stochastic_depth.klass: 'axlearn.common.layers.StochasticDepth'
model.encoder.context.context.layer.self_attention.stochastic_depth.mode: 'row'
model.encoder.context.context.layer.self_attention.structure: 'prenorm'
model.encoder.context.context.num_layers: 17
model.encoder.context.context.remat_spec['prevent_cse']: False
model.encoder.context.context.remat_spec['policy'].fn: 'jax._src.ad_checkpoint.save_only_these_names'
model.encoder.context.context.remat_spec['policy'].names_which_can_be_saved[0]: 'MultiheadAttentionXL.q_proj'
model.encoder.context.context.remat_spec['policy'].names_which_can_be_saved[1]: 'MultiheadAttentionXL.k_proj'
model.encoder.context.context.remat_spec['policy'].names_which_can_be_saved[2]: 'MultiheadAttentionXL.v_proj'
model.encoder.context.context.remat_spec['policy'].names_which_can_be_saved[3]: 'MultiheadAttentionXL.context'
model.encoder.context.context.remat_spec['policy'].names_which_can_be_saved[4]: 'MultiheadAttentionXL.o_proj'
model.encoder.context.context.repeat.drop_output.fn: 'axlearn.common.repeat._drop_by_regex'
model.encoder.context.context.repeat.drop_output.rules[0]: 'module_outputs.*'
model.encoder.context.context.repeat.klass: 'axlearn.common.conformer.ConformerRepeat'
model.encoder.context.dropout.klass: 'axlearn.common.layers.Dropout'
model.encoder.context.dropout.rate: 0.1
model.encoder.context.input_linear.bias: True
model.encoder.context.input_linear.klass: 'axlearn.common.layers.Linear'
model.encoder.context.input_linear.param_partition_spec[0]: None
model.encoder.context.input_linear.param_partition_spec[1]: None
model.encoder.context.klass: 'axlearn.audio.encoder_asr.SpeechContextNetwork'
model.encoder.context.pos_emb.klass: 'axlearn.common.attention.SinusoidalPositionalEmbedding'
model.encoder.context.pos_emb.max_timescale: 10000
model.encoder.context.pos_emb.min_timescale: 1
model.encoder.dim: 512
model.encoder.feature.augmenter.freq_mask_sampler.klass: 'axlearn.audio.spectrum_augmenter.MaskSampler'
model.encoder.feature.augmenter.freq_mask_sampler.max_mask_length: 27
model.encoder.feature.augmenter.freq_mask_sampler.max_num_masks: 2
model.encoder.feature.augmenter.klass: 'axlearn.audio.spectrum_augmenter.SpectrumAugmenter'
model.encoder.feature.augmenter.time_mask_sampler.klass: 'axlearn.audio.spectrum_augmenter.MaskSampler'
model.encoder.feature.augmenter.time_mask_sampler.max_mask_length_ratio: 0.05
model.encoder.feature.augmenter.time_mask_sampler.max_num_masks: 10
model.encoder.feature.frontend.fft_size: 'axlearn.audio.frontend_utils.next_power_of_2'
model.encoder.feature.frontend.frame_size_ms: 25
model.encoder.feature.frontend.hop_size_ms: 10
model.encoder.feature.frontend.klass: 'axlearn.audio.frontend.LogMelFrontend'
model.encoder.feature.frontend.mel_floor: 1e-08
model.encoder.feature.frontend.num_filters: 80
model.encoder.feature.frontend.output_dim: 1
model.encoder.feature.frontend.pre_emphasis.coeff: 0.97
model.encoder.feature.frontend.pre_emphasis.fn: 'axlearn.audio.frontend._pre_emphasis'
model.encoder.feature.frontend.sample_rate: 16000
model.encoder.feature.frontend.spectrogram.fn: 'axlearn.audio.frontend._log_mel_spectrogram'
model.encoder.feature.klass: 'axlearn.audio.encoder_asr.SpeechFeatureLayer'
model.encoder.feature.output_dim: 512
model.encoder.feature.subsampler.activation: 'nn.relu'
model.encoder.feature.subsampler.conv.bias: True
model.encoder.feature.subsampler.conv.klass: 'axlearn.common.layers.Conv2DWith1DPadding'
model.encoder.feature.subsampler.conv.num_input_dim_groups: 1
model.encoder.feature.subsampler.conv.padding[0][0]: 1
model.encoder.feature.subsampler.conv.padding[0][1]: 1
model.encoder.feature.subsampler.conv.padding[1][0]: 1
model.encoder.feature.subsampler.conv.padding[1][1]: 1
model.encoder.feature.subsampler.conv.param_partition_spec[0]: None
model.encoder.feature.subsampler.conv.param_partition_spec[1]: None
model.encoder.feature.subsampler.conv.param_partition_spec[2]: None
model.encoder.feature.subsampler.conv.param_partition_spec[3]: None
model.encoder.feature.subsampler.conv.strides[0]: 2
model.encoder.feature.subsampler.conv.strides[1]: 2
model.encoder.feature.subsampler.conv.window[0]: 3
model.encoder.feature.subsampler.conv.window[1]: 3
model.encoder.feature.subsampler.input_dim: 1
model.encoder.feature.subsampler.klass: 'axlearn.audio.subsamplers.ConvSubSampler'
model.encoder.klass: 'axlearn.audio.encoder_asr.ASREncoder'
model.klass: 'axlearn.audio.model_asr.ASRModel'
name: 'librispeech_trainer'
prune_empty_state_updates: True
save_input_iterator: False
start_trace_process_indices[0]: 0
summary_writer.klass: 'axlearn.common.summary_writer.SummaryWriter'
summary_writer.write_every_n_steps: 200